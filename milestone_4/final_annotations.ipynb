{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Final Annotations\n",
    "#### ... and producing dataframes for analysis!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import altair as alt \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('data_server')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Altair related settings\n",
    "# Save a vega-lite spec and a PNG blob for each plot in the notebook\n",
    "alt.renderers.enable('mimetype')\n",
    "# Handle large data sets without embedding them in the notebook\n",
    "alt.data_transformers.enable('data_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "PATH_parsed = '../data/parsed/'\n",
    "PATH_annotated = '../data/annotated/'\n",
    "PATH_processed = '../data/processed/'\n",
    "PATH_df = '../data/dataframes/'\n",
    "PATH_final = '../data/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports from Ruby script must be re-formatted...\n",
    "def convert_str_to_list(s):\n",
    "    \"\"\"Converts string representation of list into list\"\"\"\n",
    "    return s.strip('[]').split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print annotation stats, produce data frames for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS FOR ANNOTATED\n",
      "Parsing files in jessie...\n",
      "4369 annotations over 108 courses\n",
      "\n",
      "Parsing files in jinhong...\n",
      "1341 annotations over 131 courses\n",
      "\n",
      "Parsing files in jae...\n",
      "5647 annotations over 102 courses\n",
      "\n",
      "Parsing files in min...\n",
      "1924 annotations over 180 courses\n",
      "\n",
      "Parsing files in biya...\n",
      "5229 annotations over 105 courses\n",
      "\n",
      "COMPLETE!!\n"
     ]
    }
   ],
   "source": [
    "print(\"STATS FOR ANNOTATED\")\n",
    "stats_annotated = {}\n",
    "pre_filter_annotations = {}\n",
    "\n",
    "for folder in os.listdir(PATH_annotated):\n",
    "    if os.path.isdir(PATH_annotated + folder):\n",
    "        print(f\"Parsing files in {folder}...\")\n",
    "        annotator_df = pd.DataFrame()\n",
    "        course_count = 0\n",
    "        annotation_count = 0\n",
    "        empty_courses = 0\n",
    "        \n",
    "        for file in os.listdir(PATH_annotated + folder):\n",
    "            if file != '.DS_Store':\n",
    "                fn = PATH_annotated + folder + '/' + file\n",
    "                course_count += 1\n",
    "                with open(fn, 'r') as f:\n",
    "                    size = len(f.readlines())\n",
    "                    annotation_count += size\n",
    "                    if size > 0:\n",
    "                        incoming_df = pd.read_csv(PATH_annotated + folder + '/' + file, delimiter='\\t', header=None)\n",
    "                        incoming_df = incoming_df.fillna(\"\")\n",
    "                        incoming_df.columns = [\"category\", \"reading\"]\n",
    "                        incoming_df[\"course\"] = file.split(\".\")[0]\n",
    "                        annotator_df = pd.concat([annotator_df, incoming_df], ignore_index=True)\n",
    "                    else:\n",
    "                        empty_courses += 1\n",
    "                        \n",
    "        print(f\"{annotation_count} annotations over {course_count} courses\")\n",
    "        print()\n",
    "        \n",
    "        stats_annotated[folder] = {'annotations': annotation_count, 'courses': course_count}\n",
    "        pre_filter_annotations[folder] = annotator_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"COMPLETE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data frames for analysis\n",
    "pre_filter_annotations['jae'].to_csv(PATH_df + 'pre_filter_annotations_by_' + 'jae' + '.tsv', sep='\\t', index=False)\n",
    "pre_filter_annotations['biya'].to_csv(PATH_df + 'pre_filter_annotations_by_' + 'biya' + '.tsv', sep='\\t', index=False)\n",
    "\n",
    "pre_filter_annotations['jinhong'].to_csv(PATH_df + 'pre_filter_annotations_by_' + 'jinhong' + '.tsv', sep='\\t', index=False)\n",
    "pre_filter_annotations['min'].to_csv(PATH_df + 'pre_filter_annotations_by_' + 'min' + '.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS FOR PROCESSED\n",
      "Parsing files in jessie...\n",
      "4095 annotations over 108 courses\n",
      "\n",
      "Parsing files in jinhong...\n",
      "1307 annotations over 133 courses\n",
      "\n",
      "Parsing files in jae...\n",
      "5255 annotations over 102 courses\n",
      "\n",
      "Parsing files in min...\n",
      "1869 annotations over 180 courses\n",
      "\n",
      "Parsing files in biya...\n",
      "5116 annotations over 105 courses\n",
      "\n",
      "COMPLETE!!\n"
     ]
    }
   ],
   "source": [
    "print(\"STATS FOR PROCESSED\")\n",
    "stats_processed = {}\n",
    "pre_parsing_annotations = {}\n",
    "\n",
    "for folder in os.listdir(PATH_processed):\n",
    "    if os.path.isdir(PATH_processed + folder):\n",
    "        print(f\"Parsing files in {folder}...\")\n",
    "        course_count = 0\n",
    "        annotation_count = 0\n",
    "        empty_courses = 0\n",
    "        \n",
    "        for file in os.listdir(PATH_processed + folder):\n",
    "            if file != '.DS_Store':\n",
    "                fn = PATH_processed + folder + '/' + file\n",
    "                course_count += 1\n",
    "                with open(fn, 'r') as f:\n",
    "                    size = len(f.readlines())\n",
    "                    annotation_count += size\n",
    "                    if size > 0:\n",
    "                        incoming_df = pd.read_csv(PATH_processed + folder + '/' + file, delimiter='\\t', header=None)\n",
    "                        incoming_df = incoming_df.fillna(\"\")\n",
    "                        incoming_df.columns = [\"category\", \"reading\"]\n",
    "                        incoming_df[\"course\"] = file.split(\".\")[0]\n",
    "                        annotator_df = pd.concat([annotator_df, incoming_df], ignore_index=True)\n",
    "                    else:\n",
    "                        empty_courses += 1\n",
    "        print(f\"{annotation_count} annotations over {course_count} courses\")\n",
    "        print()\n",
    "        \n",
    "        stats_processed[folder] = {'annotations': annotation_count, 'courses': course_count}\n",
    "        pre_parsing_annotations[folder] = annotator_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "print(\"COMPLETE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS FOR PARSED\n",
      "Parsing files in jessie...\n",
      "3295 annotations over 96 courses\n",
      "\n",
      "Parsing files in jinhong...\n",
      "1200 annotations over 131 courses\n",
      "\n",
      "Parsing files in jae...\n",
      "3078 annotations over 86 courses\n",
      "\n",
      "Parsing files in min...\n",
      "1722 annotations over 177 courses\n",
      "\n",
      "Parsing files in biya...\n",
      "3125 annotations over 90 courses\n",
      "\n",
      "COMPLETE!!\n"
     ]
    }
   ],
   "source": [
    "annotations = {}\n",
    "\n",
    "print(\"STATS FOR PARSED\")\n",
    "stats_parsed = {}\n",
    "\n",
    "for folder in os.listdir(PATH_parsed):\n",
    "    if os.path.isdir(PATH_parsed + folder):\n",
    "        print(f\"Parsing files in {folder}...\")\n",
    "        annotator_df = pd.DataFrame()\n",
    "        course_count = 0\n",
    "        annotation_count = 0\n",
    "        empty_courses = 0\n",
    "        \n",
    "        for file in os.listdir(PATH_parsed + folder):\n",
    "            if file != '.DS_Store':\n",
    "                fn = PATH_parsed + folder + '/' + file\n",
    "                course_count += 1\n",
    "                with open(fn, 'r') as f:\n",
    "                    size = len(f.readlines())\n",
    "                    annotation_count += size\n",
    "                    if size > 0:\n",
    "                        incoming_df = pd.read_csv(PATH_parsed + folder + '/' + file, delimiter='\\t', header=None)\n",
    "                        incoming_df = incoming_df.fillna(\"\")\n",
    "                        incoming_df.columns = [\"category\", \"author\", \"title\", \"type\", \"collection\", \"year\"]\n",
    "                        incoming_df[\"course\"] = file.split(\".\")[0]\n",
    "                        #incoming_df[\"author\"] = incoming_df[\"author\"].apply(convert_str_to_list_author)\n",
    "                        incoming_df[[\"title\", \"type\", \"collection\", \"year\"]] = incoming_df[[\"title\", \"type\", \"collection\", \"year\"]].applymap(convert_str_to_list)\n",
    "                        incoming_df[[\"title\", \"type\", \"collection\", \"year\"]] = incoming_df[[\"title\", \"type\", \"collection\", \"year\"]].applymap(lambda x: x[0])\n",
    "                        incoming_df[[\"title\", \"type\", \"collection\", \"year\"]] = incoming_df[[\"title\", \"type\", \"collection\", \"year\"]].applymap(lambda x: x.strip(\"\\\"\"))\n",
    "\n",
    "                        annotator_df = pd.concat([annotator_df, incoming_df], ignore_index=True)\n",
    "                    else:\n",
    "                        empty_courses += 1\n",
    "                        \n",
    "        print(f\"{annotation_count} annotations over {course_count} courses\")\n",
    "        print()\n",
    "        \n",
    "        annotations[folder] = annotator_df.drop_duplicates(ignore_index=True)\n",
    "        stats_parsed[folder] = {'annotations': annotation_count, 'courses': course_count}\n",
    "\n",
    "\n",
    "print(\"COMPLETE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>collection</th>\n",
       "      <th>year</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optional</td>\n",
       "      <td>[{:family=&gt;\"Ott\", :given=&gt;\"E.\"}, {:family=&gt;\"Sa...</td>\n",
       "      <td>Coping with Chaos</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1994</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optional</td>\n",
       "      <td>[{:family=&gt;\"Wilks\", :given=&gt;\"D.\"}]</td>\n",
       "      <td>Statistical Methods in the Atmospheric Sciences</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optional</td>\n",
       "      <td>[{:family=&gt;\"Wunsch\", :given=&gt;\"C.\"}]</td>\n",
       "      <td>The Ocean Circulation Inverse Problem</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1996</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optional</td>\n",
       "      <td>[{:family=&gt;\"Kalnay\", :given=&gt;\"E.\"}]</td>\n",
       "      <td>Atmospheric Modeling</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2003</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Required</td>\n",
       "      <td>[{:family=&gt;\"Grassberger\", :given=&gt;\"P.\"}, {:fam...</td>\n",
       "      <td>Characterization of Strange Attractors</td>\n",
       "      <td>article-journal</td>\n",
       "      <td>Physical Review Letters</td>\n",
       "      <td>1983</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                             author  \\\n",
       "0  Optional  [{:family=>\"Ott\", :given=>\"E.\"}, {:family=>\"Sa...   \n",
       "1  Optional                 [{:family=>\"Wilks\", :given=>\"D.\"}]   \n",
       "2  Optional                [{:family=>\"Wunsch\", :given=>\"C.\"}]   \n",
       "3  Optional                [{:family=>\"Kalnay\", :given=>\"E.\"}]   \n",
       "4  Required  [{:family=>\"Grassberger\", :given=>\"P.\"}, {:fam...   \n",
       "\n",
       "                                             title             type  \\\n",
       "0                                Coping with Chaos                    \n",
       "1  Statistical Methods in the Atmospheric Sciences                    \n",
       "2            The Ocean Circulation Inverse Problem                    \n",
       "3                             Atmospheric Modeling                    \n",
       "4           Characterization of Strange Attractors  article-journal   \n",
       "\n",
       "                collection  year course  \n",
       "0                           1994   1022  \n",
       "1                           1995   1022  \n",
       "2                           1996   1022  \n",
       "3                           2003   1022  \n",
       "4  Physical Review Letters  1983   1022  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview a dataframe, for annotator == biya\n",
    "annotations['biya'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate annotator stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>annotator</th>\n",
       "      <th>annotations</th>\n",
       "      <th>courses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>annotated</td>\n",
       "      <td>jessie</td>\n",
       "      <td>4369</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotated</td>\n",
       "      <td>jinhong</td>\n",
       "      <td>1341</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotated</td>\n",
       "      <td>jae</td>\n",
       "      <td>5647</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annotated</td>\n",
       "      <td>min</td>\n",
       "      <td>1924</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annotated</td>\n",
       "      <td>biya</td>\n",
       "      <td>5229</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>processed</td>\n",
       "      <td>jessie</td>\n",
       "      <td>4095</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>processed</td>\n",
       "      <td>jinhong</td>\n",
       "      <td>1307</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>processed</td>\n",
       "      <td>jae</td>\n",
       "      <td>5255</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>processed</td>\n",
       "      <td>min</td>\n",
       "      <td>1869</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>processed</td>\n",
       "      <td>biya</td>\n",
       "      <td>5116</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>parsed</td>\n",
       "      <td>jessie</td>\n",
       "      <td>3295</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>parsed</td>\n",
       "      <td>jinhong</td>\n",
       "      <td>1200</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>parsed</td>\n",
       "      <td>jae</td>\n",
       "      <td>3078</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>parsed</td>\n",
       "      <td>min</td>\n",
       "      <td>1722</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>parsed</td>\n",
       "      <td>biya</td>\n",
       "      <td>3125</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        batch annotator  annotations  courses\n",
       "0   annotated    jessie         4369      108\n",
       "1   annotated   jinhong         1341      131\n",
       "2   annotated       jae         5647      102\n",
       "3   annotated       min         1924      180\n",
       "4   annotated      biya         5229      105\n",
       "5   processed    jessie         4095      108\n",
       "6   processed   jinhong         1307      133\n",
       "7   processed       jae         5255      102\n",
       "8   processed       min         1869      180\n",
       "9   processed      biya         5116      105\n",
       "10     parsed    jessie         3295       96\n",
       "11     parsed   jinhong         1200      131\n",
       "12     parsed       jae         3078       86\n",
       "13     parsed       min         1722      177\n",
       "14     parsed      biya         3125       90"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize stats in table\n",
    "stats_annotated_df = pd.DataFrame(stats_annotated).T\n",
    "stats_processed_df = pd.DataFrame(stats_processed).T\n",
    "stats_parsed_df = pd.DataFrame(stats_parsed).T\n",
    "\n",
    "annotation_stats = pd.concat([stats_annotated_df, stats_processed_df, stats_parsed_df], keys=['annotated', 'processed','parsed']).reset_index().rename(columns={'level_0': 'batch', 'level_1': 'annotator'})\n",
    "annotation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_annotated_df_courses = stats_annotated_df.reset_index().rename(columns={'index': 'annotator'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v4+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v4.17.0.json",
       "config": {
        "axis": {
         "grid": false,
         "labelFontSize": 15,
         "titleFontSize": 20
        },
        "title": {
         "align": "center",
         "dy": -20,
         "fontSize": 18
        },
        "view": {
         "continuousHeight": 300,
         "continuousWidth": 400,
         "strokeWidth": 0
        }
       },
       "data": {
        "url": "http://localhost:52183/cffde199df58a4f61aaf1bf46591c7c7.json"
       },
       "layer": [
        {
         "encoding": {
          "color": {
           "field": "annotator",
           "legend": null,
           "type": "nominal"
          },
          "x": {
           "field": "courses",
           "stack": false,
           "title": null,
           "type": "quantitative"
          },
          "y": {
           "field": "annotator",
           "sort": "-x",
           "title": null,
           "type": "nominal"
          }
         },
         "height": 150,
         "mark": "bar",
         "title": "Number of Courses Covered by Each Annotator",
         "width": 500
        },
        {
         "encoding": {
          "color": {
           "field": "annotator",
           "legend": null,
           "type": "nominal"
          },
          "text": {
           "field": "courses",
           "type": "quantitative"
          },
          "x": {
           "field": "courses",
           "type": "quantitative"
          },
          "y": {
           "field": "annotator",
           "sort": "-x",
           "type": "nominal"
          }
         },
         "height": 150,
         "mark": {
          "align": "left",
          "dx": 5,
          "size": 18,
          "type": "text"
         },
         "title": "Number of Courses Covered by Each Annotator",
         "width": 500
        }
       ]
      },
      "text/plain": [
       "<VegaLite 4 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot stats as bar chart\n",
    "alt.themes.enable('default')\n",
    "\n",
    "base = alt.Chart(stats_annotated_df_courses, title=\"Number of Courses Covered by Each Annotator\").mark_bar().encode(\n",
    "    x=alt.X('courses', title=None, stack=False),\n",
    "    y=alt.Y('annotator', sort='-x', title=None),\n",
    "    color=alt.Color('annotator', legend=None)\n",
    "    ).properties(width=500, height=150)\n",
    "\n",
    "text = base.mark_text(dx=5, size=18, align='left').encode(\n",
    "    y=alt.Y('annotator', sort='-x'),\n",
    "    x=alt.X('courses'),\n",
    "    text=alt.Text('courses')\n",
    ")\n",
    "\n",
    "((base + text)\n",
    " .configure_axis(labelFontSize=15, titleFontSize=20, grid=False)\n",
    " .configure_view(strokeWidth=0)\n",
    " .configure_title(fontSize=18, dy=-20, align='center')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v4+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v4.17.0.json",
       "config": {
        "axis": {
         "grid": false,
         "labelFontSize": 15,
         "titleFontSize": 20
        },
        "legend": {
         "cornerRadius": 10,
         "fillColor": "#FFFFFF",
         "labelFontSize": 20,
         "orient": "right",
         "padding": 10,
         "strokeColor": "gray",
         "titleFontSize": 20
        },
        "title": {
         "align": "center",
         "dy": -20,
         "fontSize": 20
        },
        "view": {
         "continuousHeight": 300,
         "continuousWidth": 400,
         "strokeWidth": 0
        }
       },
       "data": {
        "url": "http://localhost:52183/ed7a0be36dba86e95b2858a47e79f13a.json"
       },
       "facet": {
        "row": {
         "field": "annotator",
         "header": {
          "labelFontSize": 20
         },
         "sort": [
          "jae",
          "biya",
          "jessie",
          "min",
          "jinhong"
         ],
         "title": null,
         "type": "nominal"
        }
       },
       "spec": {
        "layer": [
         {
          "encoding": {
           "color": {
            "field": "batch",
            "legend": {
             "title": null
            },
            "type": "nominal"
           },
           "x": {
            "field": "annotations",
            "stack": false,
            "title": null,
            "type": "quantitative"
           },
           "y": {
            "axis": null,
            "field": "batch",
            "sort": [
             "annotated",
             "processed",
             "parsed"
            ],
            "title": null,
            "type": "nominal"
           }
          },
          "height": 80,
          "mark": "bar",
          "width": 500
         },
         {
          "encoding": {
           "color": {
            "field": "batch",
            "legend": {
             "title": null
            },
            "type": "nominal"
           },
           "text": {
            "field": "annotations",
            "format": ",",
            "type": "quantitative"
           },
           "x": {
            "field": "annotations",
            "stack": false,
            "type": "quantitative"
           },
           "y": {
            "field": "batch",
            "sort": [
             "annotated",
             "processed",
             "parsed"
            ],
            "type": "nominal"
           }
          },
          "height": 80,
          "mark": {
           "align": "left",
           "dx": 5,
           "size": 18,
           "type": "text"
          },
          "width": 500
         }
        ]
       },
       "title": "Number of Annotations After Each Step by Annotator"
      },
      "text/plain": [
       "<VegaLite 4 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot stats as bar chart\n",
    "alt.themes.enable('default')\n",
    "\n",
    "base = alt.Chart(annotation_stats).mark_bar().encode(\n",
    "    x=alt.X('annotations', stack=False, title=None),\n",
    "    y=alt.Y('batch', sort=['annotated', 'processed', 'parsed'], title=None, axis=None),\n",
    "    color=alt.Color('batch', legend=alt.Legend(title=None))\n",
    "    ).properties(width=500, height=80)\n",
    "\n",
    "text = base.mark_text(dx=5, size=18, align='left').encode(\n",
    "    y=alt.Y('batch', sort=['annotated', 'processed', 'parsed']),\n",
    "    x=alt.X('annotations', stack=False),\n",
    "    text=alt.Text('annotations', format=',')\n",
    ")\n",
    "\n",
    "((base + text).facet(\n",
    "    title=\"Number of Annotations After Each Step by Annotator\",\n",
    "    row=alt.Row('annotator', sort= ['jae', 'biya', 'jessie', 'min', 'jinhong'], header=alt.Header(labelFontSize=20), title=None),\n",
    ").configure_axis(labelFontSize=15, titleFontSize=20, grid=False)\n",
    " .configure_view(strokeWidth=0)\n",
    " .configure_title(fontSize=20, dy=-20, align='center')\n",
    " .configure_legend(\n",
    "    strokeColor='gray',\n",
    "    fillColor='#FFFFFF',\n",
    "    padding=10,\n",
    "    cornerRadius=10,\n",
    "    orient='right',\n",
    "    labelFontSize=20,\n",
    "    titleFontSize=20\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data frames for interannotation agreement analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as tsv\n",
    "for annotator, df in annotations.items():\n",
    "    df.to_csv(PATH_df + 'annotations_by_' + annotator + '.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find set of unique courses, for each annotator\n",
    "courses = {annotator: set(df[\"course\"].value_counts().keys()) for annotator, df in annotations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match agreement partners, slice dataframe for matching courses \n",
    "for_agreement = {}\n",
    "\n",
    "for_agreement[\"biya\"] = annotations[\"biya\"][annotations[\"biya\"].course.isin(list(courses[\"biya\"].intersection(courses[\"jae\"])))]\n",
    "for_agreement[\"jae\"] = annotations[\"jae\"][annotations[\"jae\"].course.isin(list(courses[\"biya\"].intersection(courses[\"jae\"])))]\n",
    "\n",
    "for_agreement[\"jinhong\"] = annotations[\"jinhong\"][annotations[\"jinhong\"].course.isin(list(courses[\"jinhong\"].intersection(courses[\"min\"])))]\n",
    "for_agreement[\"min\"] = annotations[\"min\"][annotations[\"min\"].course.isin(list(courses[\"jinhong\"].intersection(courses[\"min\"])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_agreement[\"biya\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as tsv\n",
    "for annotator, df in for_agreement.items():\n",
    "    df.to_csv(PATH_df + 'annotations_by_' + annotator + '.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce final version annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce the final version, we decided on the following rules on how to resolve conflicts in our interannotations:\n",
    "\n",
    "- If both annotators agree on the category of the reading, we include it, as is. \n",
    "- If the annotators disagree on the category of the reading (one vote on \"required, one vote on \"optional\"), we include the reading as \"required\". The rationale behind this is that it is better for a student to read the reading and find out that it was actually optional, than to not read the reading and find out later that it was actually requried. \n",
    "- If one person annotated a reading that is completely missed by the other, we include the reading. In such cases, the person who _did_ annotate gets the say of the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_final(df, annotator1, annotator2):\n",
    "    \"\"\"Make final annotation decision\"\"\"\n",
    "    # Agree\n",
    "    if (df['_merge'] == 'both') and (df['category_'+annotator1] == df['category_'+annotator1]):\n",
    "        return df['category_'+annotator1]\n",
    "    # Disagree\n",
    "    elif (df['_merge'] == 'both') and (df['category_'+annotator1] != df['category_'+annotator1]):\n",
    "        return 'Required'\n",
    "    # Unknowns\n",
    "    elif (df['_merge'] == 'left_only'):\n",
    "        return df['category_'+annotator1]\n",
    "    elif (df['_merge'] == 'right_only'):\n",
    "        return df['category_'+annotator2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_final_annotation_files(annotator1, annotator2):\n",
    "    \"\"\"Export final annotation tsv files\"\"\"\n",
    "    merge_df = pd.merge(\n",
    "        for_agreement[annotator1], \n",
    "        for_agreement[annotator2], \n",
    "        how='outer', \n",
    "        on=['author', 'title', 'type', 'collection', 'year', 'course'], \n",
    "        indicator=True, \n",
    "        suffixes=['_'+annotator1, '_'+annotator2]\n",
    "    )\n",
    "    \n",
    "    courses = sorted(merge_df.course.value_counts().keys())\n",
    "\n",
    "    # We will generate a .tsv file for each course, to look like our other annotations\n",
    "    for c in tqdm(courses):\n",
    "        slice_df = merge_df[merge_df.course==c].copy()\n",
    "        decisions = []\n",
    "        \n",
    "        for row in slice_df.iterrows():\n",
    "            decisions.append(decide_final(row[1], annotator1, annotator2))\n",
    "        \n",
    "        slice_df['category'] = decisions\n",
    "        slice_df = slice_df.loc[:, ~slice_df.columns.isin(['course', 'category_'+annotator1, 'category_'+annotator2])]\n",
    "        slice_df.to_csv(PATH_final + c + '.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_final_annotation_files('biya', 'jae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_final_annotation_files('min', 'jinhong')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
