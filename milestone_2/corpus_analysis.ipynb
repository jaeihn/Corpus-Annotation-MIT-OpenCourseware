{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e01ccc56-c1a3-4f3d-b485-8fafef7a9d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mit_syllabus_corpus = []\n",
    "mit_syllabus_corpus_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6285093-faac-48bf-a3d5-ec34c1bb2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for number in range(2494):\n",
    "\n",
    "    HTMLFile = open(\"concat/\" + str(number) + \".html\", \"r\")\n",
    "    index = HTMLFile.read()\n",
    "    S = BeautifulSoup(index, 'lxml')\n",
    "\n",
    "    if S.body != None:\n",
    "        mit_syllabus_corpus.append(S.body.get_text().replace(\"\\n\", \"\").replace(\"\\xa0\", \" \"))\n",
    "        mit_syllabus_corpus_words += S.body.get_text().replace(\"\\n\", \"\").replace(\"\\xa0\", \" \").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe395ac3-f50f-43f2-9d82-429e5d6cfa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Adapted from COLX 521 Lecture 4\n",
    "\n",
    "def average_word_length(words):\n",
    "    total_words = 0\n",
    "    total_chars = 0\n",
    "    for word in words:\n",
    "        total_words += 1\n",
    "        total_chars += len(word)\n",
    "    return total_chars/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60e4f81b-146d-4332-aa7d-6ab8781099ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank, webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6ba8ff3f-ee4c-4c41-b57d-cb176104cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webtext\n",
      "Number of words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "396733"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"webtext\")\n",
    "print(\"Number of words:\")\n",
    "len(webtext.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb75de63-3dac-4b19-b95a-37c8bdf19761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treebank\n",
      "Number of words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100676"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"treebank\")\n",
    "print(\"Number of words:\")\n",
    "len(treebank.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df0198ff-45b0-42dc-a15c-3dbaf6319481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT syllabus corpus\n",
      "Number of words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6256086"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MIT syllabus corpus\")\n",
    "print(\"Number of words:\")\n",
    "len(mit_syllabus_corpus_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1727e1a-fe6d-4b29-ae8b-650ad1d4b08d",
   "metadata": {},
   "source": [
    "For number of words, MIT syllabus corpus has 6256086 words, treebank corpus has 100676 words, and webtext corpus has 396733 words. I think the reason why MIT syllabus corpus has much more words is because there are around 2500 syllabuses and each syllabus has very detailed description of a course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3ef0f0c6-a367-4733-87be-4e36e838231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treebank\n",
      "Average word length:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.406154396281139"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"treebank\")\n",
    "print(\"Average word length:\")\n",
    "average_word_length(treebank.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8830d651-eeb2-4a2f-8002-46a1cc3a6d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT syllabus corpus\n",
      "Average word length:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.143507298333175"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MIT syllabus corpus\")\n",
    "print(\"Average word length:\")\n",
    "average_word_length(mit_syllabus_corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e9e0b7d-7970-41fa-9f6a-56551dd94b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webtext\n",
      "Average word length:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.552701691061747"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"webtext\")\n",
    "print(\"Average word length:\")\n",
    "average_word_length(webtext.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2108c5-51e4-472e-bf8c-3621bdf7751d",
   "metadata": {},
   "source": [
    "For average word length, MIT syllabus corpus's is 6.143507298333175, treebank's is 4.406154396281139, webtext's is 3.552701691061747. I think the reason why the average word length of MIT syllabus corpus is the highest is because it has more proper nouns including author's name and academic terminology. Webtext has the lowest may be because most of the words in webtext come from online discussion forums and they are mostly simple daily English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f77330e1-2eb3-4927-9e68-ebfafec93aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from COLX 521 Lecture 4\n",
    "\n",
    "def get_simple_stats(corpus):\n",
    "    #num_chars = sum([len(word) for word in corpus.words()])\n",
    "    num_words = len(corpus.words())\n",
    "    #num_sents = len(corpus.sents())\n",
    "    num_texts = len(corpus.fileids())\n",
    "    #print(num_texts)\n",
    "    print(\"average text length\")\n",
    "    print(num_words/num_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a893410d-6fcb-4189-874e-0f1c49338f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treebank\n",
      "average text length\n",
      "505.90954773869345\n"
     ]
    }
   ],
   "source": [
    "print(\"treebank\")\n",
    "get_simple_stats(treebank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1435db5b-c52f-40df-a5ff-7c0842c225b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webtext\n",
      "average text length\n",
      "66122.16666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"webtext\")\n",
    "get_simple_stats(webtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5e1cb25b-aebb-438b-8ed5-8ad9a1c68323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT syllabus corpus\n",
      "average text length\n",
      "2560.821121571838\n"
     ]
    }
   ],
   "source": [
    "print(\"MIT syllabus corpus\")\n",
    "print(\"average text length\")\n",
    "print(len(mit_syllabus_corpus_words)/len(mit_syllabus_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269528e-f9d9-4d45-8841-cf762b1d68bb",
   "metadata": {},
   "source": [
    "For average text length, MIT syllabus corpus's is 2560.821121571838, webtext's is 66122.16666666667, treebank's is 505.90954773869345. I think the reason why webtext's is the highest is because it has least amount of texts which is only 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "80513ee7-b311-4ff7-bb05-761c0f31ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from COLX 521 Lecture 4\n",
    "\n",
    "def type_token_ratio(words):\n",
    "    types = list(set(words))\n",
    "    return len(types) / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eaf988c6-3630-4f8e-b25b-574efdc674db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT syllabus corpus\n",
      "type token radio\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11294314048751887"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MIT syllabus corpus\")\n",
    "print(\"type token radio\")\n",
    "type_token_ratio(mit_syllabus_corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5206588a-279a-476f-ae3a-51821209b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treebank\n",
      "type token radio\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12324685128531129"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"treebank\")\n",
    "print(\"type token radio\")\n",
    "type_token_ratio(treebank.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d97b499f-c19b-462e-83b9-3464927fe6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webtext\n",
      "type token radio\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05428840051117502"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"webtext\")\n",
    "print(\"type token radio\")\n",
    "type_token_ratio(webtext.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca265c7-d051-4aeb-b86c-d4702fd6372d",
   "metadata": {},
   "source": [
    "For type token radio, MIT syllabus corpus's is 0.11294314048751887, webtext's is 0.05428840051117502, treebank's is 0.12324685128531129. MIT syllabus corpus's is close to treebank's and webtext's is much lower. I think MIT syllabus corpus and treebank have higher lexical richness may be because they have more proper nouns and terminologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc4f76f9-1050-4910-afc6-38c67239146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT syllabus corpus\n",
      "['chapters', 'urban', 'learning', 'their', 'd.', 'write', 'case', 'video', 'de', 'may', 'presentation', 'c.', 'data', 'american', 'assignments', 'sessions', 'development', 'used', 'exam', 'due', '5', 'study', '=', 'week,', 'reading', 'assignment', 'following', 'use', 'our', 'writing', 'questions', 'introduction', 'r.', 'google', 's.', 'part', 'discussion', 'ed.', '[preview', 'social', 'theory', 'session', 'p.', 'an', 'student', 'a.', 'readings', 'analysis', 'al.', 'research', 'm.', 'problem', 'edited', 'these', '(pdf)', '4', 'science', 'review', 'this', 'et', 'journal', 'york,', '(pdf', 'design', 'ny:', 'lecture', 'j.', 'mit', 'paper', 'we', '/', 'with', '3', 'as', 'project', 'or', 'final', 'each', 'â€œthe', 'are', 'how', 'university', 'set', 'by', 'chapter', 'be', 'class', 'students', 'press,', 'pp.', 'your', 'no.', 'course', 'for', 'will', 'isbn:', 'in', 'the', 'of', 'and']\n",
      "Treebank\n",
      "['many', 'bonds', 'but', 'investment', 'recent', 'companies', 'such', 'last', 'profit', 'department', 'executive', 'yesterday', 'bank', 'price', 'funds', 'exchange', 'cents', 'investors', 'stocks', 'board', 'could', '*ich*-1', 'index', 'futures', 'because', 'japan', 'federal', 'co.', 'sales', 'york', 'from', 'government', 'they', 'japanese', 'who', 'prices', 'their', 'years', 'more', 'inc.', '*t*-3', 'new', 'been', 'also', 'had', '-lrb-', 'an', 'than', '-rrb-', 'shares', 'share', 'corp.', 'as', 'program', 'were', 'would', 'he', '*-3', ';', 'which', 'billion', 'president', 'for', 'was', 'trading', 'stock', 'by', 'market', '--', 'at', 'year', 'says', 'u.s.', 'that', 'has', 'company', 'of', 'in', 'its', \"n't\", '*t*-2', '*-2', 'mr.', 'million', 'to', '%', 'a', 'said', \"''\", '``', '$', '*u*', '*t*-1', \"'s\", '*', '0', '*-1', 'the', '.', ',']\n",
      "Webtext\n",
      "['too', 'shit', 'little', 'after', 'back', 'have', 'think', 'manager', 'got', 'want', 'crash', 'dude', 'll', 'there', 'him', 'black', 'button', 'old', 'going', 'well', 'very', 'her', 'really', 'download', 'url', 'out', 'jack', 'right', 'good', 'go', 'bookmark', 'browser', 'boy', '***', 'all', 'lady', 'cell', 'toolbar', 'bar', 'tab', 'menu', 'does', 'he', 'up', 'firebird', 'do', 'but', 'teen', 'bookmarks', 'doesn', 'open', 'if', 'she', 'window', 'can', 'oh', ')', 'get', 'chick', 'page', 're', 'what', 'just', 'firefox', 'yeah', '(', 'know', 'on', 'woman', 'man', 'so', 'm', 'no', 'don', '[', ']', '2', 'me', 'my', 'like', 'when', '...', 'it', '1', 'not', '\"', ',', '-', 'guy', 'girl', 's', 't', '#', '!', '?', 'you', 'i', '.', \"'\", ':']\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from COLX 521 Lab 2 solution\n",
    "\n",
    "import collections\n",
    "\n",
    "def get_unigram_probs(words):\n",
    "    counts = collections.Counter([word.lower() for word in words])\n",
    "    total = sum(counts.values())\n",
    "    return {word:count/total for word,count in counts.items()}\n",
    "\n",
    "def combine_probs(prob1,prob2):\n",
    "    all_words = set(prob1.keys())\n",
    "    all_words.update(prob2.keys())\n",
    "    return {word:(prob1.get(word,0) + prob2.get(word,0))/2 for word in all_words}\n",
    "\n",
    "def subtract_probs(prob1, prob2):\n",
    "    all_words = set(prob1.keys())\n",
    "    all_words.update(prob2.keys())\n",
    "    return {word:prob1.get(word,0) - prob2.get(word,0) for word in all_words}\n",
    "\n",
    "probs_dicts = []\n",
    "#for category in categories:\n",
    "probs_dicts.append(get_unigram_probs(mit_syllabus_corpus_words))\n",
    "probs_dicts.append(get_unigram_probs(treebank.words()))\n",
    "probs_dicts.append(get_unigram_probs(webtext.words()))\n",
    "\n",
    "categories = [\"MIT syllabus corpus\", \"Treebank\", \"Webtext\"]\n",
    "\n",
    "for i in range(3):\n",
    "    current_probs = probs_dicts[i]\n",
    "    other_probs = probs_dicts[:i] + probs_dicts[i+1:]\n",
    "    comb_probs = combine_probs(other_probs[0],other_probs[1])\n",
    "    sub_probs = subtract_probs(current_probs, comb_probs)\n",
    "    sub_sorted_words = sorted(sub_probs.keys(),key=lambda x: sub_probs[x])\n",
    "    print(categories[i])\n",
    "    print(sub_sorted_words[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003c8a6-7b74-4bd0-a780-ad06d169d558",
   "metadata": {},
   "source": [
    "According to the result above, I think the words associated with MIT syllabus corpus are mostly academic missions for the course, such as reading, assignment, discussion, lecture, etc. And I think those are the metadata of the MIT syllabus corpus. Because of those metadata, MIT syllabus corpus has more proper nouns and academic terminologies so that average word length and type token radio are higher. The words associated with treebank are from different backgrounds since they are from different journal articles. And the words associated with webtext are mostly daily English words and pronouns because they are collected mostly from online discussion forums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2071afb6-53a2-44f7-93ea-bfa2c6dbdc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
