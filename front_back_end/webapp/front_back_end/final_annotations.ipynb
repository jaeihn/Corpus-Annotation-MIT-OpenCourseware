{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Final Annotations\n",
    "#### ... and producing dataframes for analysis!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import altair as alt \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('data_server')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Altair related settings\n",
    "# Save a vega-lite spec and a PNG blob for each plot in the notebook\n",
    "alt.renderers.enable('mimetype')\n",
    "# Handle large data sets without embedding them in the notebook\n",
    "alt.data_transformers.enable('data_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "PATH_parsed = '../data/parsed/'\n",
    "PATH_annotated = '../data/annotated/'\n",
    "PATH_processed = '../data/processed/'\n",
    "PATH_df = '../data/dataframes/'\n",
    "PATH_final = '../data/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports from Ruby script must be re-formatted...\n",
    "def convert_str_to_list(s):\n",
    "    \"\"\"Converts string representation of list into list\"\"\"\n",
    "    return s.strip('[]').split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print annotation stats, produce data frames for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS FOR ANNOTATED\n",
      "Parsing files in jessie...\n",
      "4369 annotations over 108 courses\n",
      "\n",
      "Parsing files in jinhong...\n",
      "1341 annotations over 131 courses\n",
      "\n",
      "Parsing files in jae...\n",
      "5647 annotations over 102 courses\n",
      "\n",
      "Parsing files in min...\n",
      "1924 annotations over 180 courses\n",
      "\n",
      "Parsing files in biya...\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '../data/annotated/biya/tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m fn \u001b[38;5;241m=\u001b[39m PATH_annotated \u001b[38;5;241m+\u001b[39m folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file\n\u001b[1;32m     16\u001b[0m course_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(f\u001b[38;5;241m.\u001b[39mreadlines())\n\u001b[1;32m     19\u001b[0m     annotation_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m size\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '../data/annotated/biya/tsv'"
     ]
    }
   ],
   "source": [
    "print(\"STATS FOR ANNOTATED\")\n",
    "stats_annotated = {}\n",
    "pre_filter_annotations = {}\n",
    "\n",
    "for folder in os.listdir(PATH_annotated):\n",
    "    if os.path.isdir(PATH_annotated + folder):\n",
    "        print(f\"Parsing files in {folder}...\")\n",
    "        annotator_df = pd.DataFrame()\n",
    "        course_count = 0\n",
    "        annotation_count = 0\n",
    "        empty_courses = 0\n",
    "        \n",
    "        for file in os.listdir(PATH_annotated + folder):\n",
    "            if file != '.DS_Store':\n",
    "                fn = PATH_annotated + folder + '/' + file\n",
    "                course_count += 1\n",
    "                with open(fn, 'r') as f:\n",
    "                    size = len(f.readlines())\n",
    "                    annotation_count += size\n",
    "                    if size > 0:\n",
    "                        incoming_df = pd.read_csv(PATH_annotated + folder + '/' + file, delimiter='\\t', header=None)\n",
    "                        incoming_df = incoming_df.fillna(\"\")\n",
    "                        incoming_df.columns = [\"category\", \"reading\"]\n",
    "                        incoming_df[\"course\"] = file.split(\".\")[0]\n",
    "                        annotator_df = pd.concat([annotator_df, incoming_df], ignore_index=True)\n",
    "                    else:\n",
    "                        empty_courses += 1\n",
    "                        \n",
    "        print(f\"{annotation_count} annotations over {course_count} courses\")\n",
    "        print()\n",
    "        \n",
    "        stats_annotated[folder] = {'annotations': annotation_count, 'courses': course_count}\n",
    "        pre_filter_annotations[folder] = annotator_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"COMPLETE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data frames for analysis\n",
    "pre_filter_annotations['jae'].to_csv(PATH_df + 'pre_filter_annotations_by_' + 'jae' + '.tsv', sep='\\t', index=False)\n",
    "pre_filter_annotations['biya'].to_csv(PATH_df + 'pre_filter_annotations_by_' + 'biya' + '.tsv', sep='\\t', index=False)\n",
    "\n",
    "pre_filter_annotations['jinhong'].to_csv(PATH_df + 'pre_filter_annotations_by_' + 'jinhong' + '.tsv', sep='\\t', index=False)\n",
    "pre_filter_annotations['min'].to_csv(PATH_df + 'pre_filter_annotations_by_' + 'min' + '.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STATS FOR PROCESSED\")\n",
    "stats_processed = {}\n",
    "pre_parsing_annotations = {}\n",
    "\n",
    "for folder in os.listdir(PATH_processed):\n",
    "    if os.path.isdir(PATH_processed + folder):\n",
    "        print(f\"Parsing files in {folder}...\")\n",
    "        course_count = 0\n",
    "        annotation_count = 0\n",
    "        empty_courses = 0\n",
    "        \n",
    "        for file in os.listdir(PATH_processed + folder):\n",
    "            if file != '.DS_Store':\n",
    "                fn = PATH_processed + folder + '/' + file\n",
    "                course_count += 1\n",
    "                with open(fn, 'r') as f:\n",
    "                    size = len(f.readlines())\n",
    "                    annotation_count += size\n",
    "                    if size > 0:\n",
    "                        incoming_df = pd.read_csv(PATH_processed + folder + '/' + file, delimiter='\\t', header=None)\n",
    "                        incoming_df = incoming_df.fillna(\"\")\n",
    "                        incoming_df.columns = [\"category\", \"reading\"]\n",
    "                        incoming_df[\"course\"] = file.split(\".\")[0]\n",
    "                        annotator_df = pd.concat([annotator_df, incoming_df], ignore_index=True)\n",
    "                    else:\n",
    "                        empty_courses += 1\n",
    "        print(f\"{annotation_count} annotations over {course_count} courses\")\n",
    "        print()\n",
    "        \n",
    "        stats_processed[folder] = {'annotations': annotation_count, 'courses': course_count}\n",
    "        pre_parsing_annotations[folder] = annotator_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "print(\"COMPLETE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = {}\n",
    "\n",
    "print(\"STATS FOR PARSED\")\n",
    "stats_parsed = {}\n",
    "\n",
    "for folder in os.listdir(PATH_parsed):\n",
    "    if os.path.isdir(PATH_parsed + folder):\n",
    "        print(f\"Parsing files in {folder}...\")\n",
    "        annotator_df = pd.DataFrame()\n",
    "        course_count = 0\n",
    "        annotation_count = 0\n",
    "        empty_courses = 0\n",
    "        \n",
    "        for file in os.listdir(PATH_parsed + folder):\n",
    "            if file != '.DS_Store':\n",
    "                fn = PATH_parsed + folder + '/' + file\n",
    "                course_count += 1\n",
    "                with open(fn, 'r') as f:\n",
    "                    size = len(f.readlines())\n",
    "                    annotation_count += size\n",
    "                    if size > 0:\n",
    "                        incoming_df = pd.read_csv(PATH_parsed + folder + '/' + file, delimiter='\\t', header=None)\n",
    "                        incoming_df = incoming_df.fillna(\"\")\n",
    "                        incoming_df.columns = [\"category\", \"author\", \"title\", \"type\", \"collection\", \"year\"]\n",
    "                        incoming_df[\"course\"] = file.split(\".\")[0]\n",
    "                        #incoming_df[\"author\"] = incoming_df[\"author\"].apply(convert_str_to_list_author)\n",
    "                        incoming_df[[\"title\", \"type\", \"collection\", \"year\"]] = incoming_df[[\"title\", \"type\", \"collection\", \"year\"]].applymap(convert_str_to_list)\n",
    "                        incoming_df[[\"title\", \"type\", \"collection\", \"year\"]] = incoming_df[[\"title\", \"type\", \"collection\", \"year\"]].applymap(lambda x: x[0])\n",
    "                        incoming_df[[\"title\", \"type\", \"collection\", \"year\"]] = incoming_df[[\"title\", \"type\", \"collection\", \"year\"]].applymap(lambda x: x.strip(\"\\\"\"))\n",
    "\n",
    "                        annotator_df = pd.concat([annotator_df, incoming_df], ignore_index=True)\n",
    "                    else:\n",
    "                        empty_courses += 1\n",
    "                        \n",
    "        print(f\"{annotation_count} annotations over {course_count} courses\")\n",
    "        print()\n",
    "        \n",
    "        annotations[folder] = annotator_df.drop_duplicates(ignore_index=True)\n",
    "        stats_parsed[folder] = {'annotations': annotation_count, 'courses': course_count}\n",
    "\n",
    "\n",
    "print(\"COMPLETE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a dataframe, for annotator == biya\n",
    "annotations['biya'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate annotator stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize stats in table\n",
    "stats_annotated_df = pd.DataFrame(stats_annotated).T\n",
    "stats_processed_df = pd.DataFrame(stats_processed).T\n",
    "stats_parsed_df = pd.DataFrame(stats_parsed).T\n",
    "\n",
    "annotation_stats = pd.concat([stats_annotated_df, stats_processed_df, stats_parsed_df], keys=['annotated', 'processed','parsed']).reset_index().rename(columns={'level_0': 'batch', 'level_1': 'annotator'})\n",
    "annotation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_annotated_df_courses = stats_annotated_df.reset_index().rename(columns={'index': 'annotator'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stats as bar chart\n",
    "alt.themes.enable('default')\n",
    "\n",
    "base = alt.Chart(stats_annotated_df_courses, title=\"Number of Courses Covered by Each Annotator\").mark_bar().encode(\n",
    "    x=alt.X('courses', title=None, stack=False),\n",
    "    y=alt.Y('annotator', sort='-x', title=None),\n",
    "    color=alt.Color('annotator', legend=None)\n",
    "    ).properties(width=500, height=150)\n",
    "\n",
    "text = base.mark_text(dx=5, size=18, align='left').encode(\n",
    "    y=alt.Y('annotator', sort='-x'),\n",
    "    x=alt.X('courses'),\n",
    "    text=alt.Text('courses')\n",
    ")\n",
    "\n",
    "((base + text)\n",
    " .configure_axis(labelFontSize=15, titleFontSize=20, grid=False)\n",
    " .configure_view(strokeWidth=0)\n",
    " .configure_title(fontSize=18, dy=-20, align='center')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stats as bar chart\n",
    "alt.themes.enable('default')\n",
    "\n",
    "base = alt.Chart(annotation_stats).mark_bar().encode(\n",
    "    x=alt.X('annotations', stack=False, title=None),\n",
    "    y=alt.Y('batch', sort=['annotated', 'processed', 'parsed'], title=None, axis=None),\n",
    "    color=alt.Color('batch', legend=alt.Legend(title=None))\n",
    "    ).properties(width=500, height=80)\n",
    "\n",
    "text = base.mark_text(dx=5, size=18, align='left').encode(\n",
    "    y=alt.Y('batch', sort=['annotated', 'processed', 'parsed']),\n",
    "    x=alt.X('annotations', stack=False),\n",
    "    text=alt.Text('annotations', format=',')\n",
    ")\n",
    "\n",
    "((base + text).facet(\n",
    "    title=\"Number of Annotations After Each Step by Annotator\",\n",
    "    row=alt.Row('annotator', sort= ['jae', 'biya', 'jessie', 'min', 'jinhong'], header=alt.Header(labelFontSize=20), title=None),\n",
    ").configure_axis(labelFontSize=15, titleFontSize=20, grid=False)\n",
    " .configure_view(strokeWidth=0)\n",
    " .configure_title(fontSize=20, dy=-20, align='center')\n",
    " .configure_legend(\n",
    "    strokeColor='gray',\n",
    "    fillColor='#FFFFFF',\n",
    "    padding=10,\n",
    "    cornerRadius=10,\n",
    "    orient='right',\n",
    "    labelFontSize=20,\n",
    "    titleFontSize=20\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data frames for interannotation agreement analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find set of unique courses, for each annotator\n",
    "courses = {annotator: set(df[\"course\"].value_counts().keys()) for annotator, df in annotations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses['biya]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match agreement partners, slice dataframe for matching courses \n",
    "for_agreement = {}\n",
    "\n",
    "for_agreement[\"biya\"] = annotations[\"biya\"][annotations[\"biya\"].course.isin(list(courses[\"biya\"].intersection(courses[\"jae\"])))]\n",
    "for_agreement[\"jae\"] = annotations[\"jae\"][annotations[\"jae\"].course.isin(list(courses[\"biya\"].intersection(courses[\"jae\"])))]\n",
    "\n",
    "for_agreement[\"jinhong\"] = annotations[\"jinhong\"][annotations[\"jinhong\"].course.isin(list(courses[\"jinhong\"].intersection(courses[\"min\"])))]\n",
    "for_agreement[\"min\"] = annotations[\"min\"][annotations[\"min\"].course.isin(list(courses[\"jinhong\"].intersection(courses[\"min\"])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_agreement[\"biya\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as tsv\n",
    "for annotator, df in for_agreement.items():\n",
    "    df.to_csv(PATH_df + 'annotations_by_' + annotator + '.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce final version annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce the final version, we decided on the following rules on how to resolve conflicts in our interannotations:\n",
    "\n",
    "- If both annotators agree on the category of the reading, we include it, as is. \n",
    "- If the annotators disagree on the category of the reading (one vote on \"required, one vote on \"optional\"), we include the reading as \"required\". The rationale behind this is that it is better for a student to read the reading and find out that it was actually optional, than to not read the reading and find out later that it was actually requried. \n",
    "- If one person annotated a reading that is completely missed by the other, we include the reading. In such cases, the person who _did_ annotate gets the say of the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_final(df, annotator1, annotator2):\n",
    "    \"\"\"Make final annotation decision\"\"\"\n",
    "    # Agree\n",
    "    if (df['_merge'] == 'both') and (df['category_'+annotator1] == df['category_'+annotator1]):\n",
    "        return df['category_'+annotator1]\n",
    "    # Disagree\n",
    "    elif (df['_merge'] == 'both') and (df['category_'+annotator1] != df['category_'+annotator1]):\n",
    "        return 'Required'\n",
    "    # Unknowns\n",
    "    elif (df['_merge'] == 'left_only'):\n",
    "        return df['category_'+annotator1]\n",
    "    elif (df['_merge'] == 'right_only'):\n",
    "        return df['category_'+annotator2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_final_annotation_files(annotator1, annotator2):\n",
    "    \"\"\"Export final annotation tsv files\"\"\"\n",
    "    merge_df = pd.merge(\n",
    "        for_agreement[annotator1], \n",
    "        for_agreement[annotator2], \n",
    "        how='outer', \n",
    "        on=['author', 'title', 'type', 'collection', 'year', 'course'], \n",
    "        indicator=True, \n",
    "        suffixes=['_'+annotator1, '_'+annotator2]\n",
    "    )\n",
    "    \n",
    "    courses = sorted(merge_df.course.value_counts().keys())\n",
    "\n",
    "    # We will generate a .tsv file for each course, to look like our other annotations\n",
    "    for c in tqdm(courses):\n",
    "        slice_df = merge_df[merge_df.course==c].copy()\n",
    "        decisions = []\n",
    "        \n",
    "        for row in slice_df.iterrows():\n",
    "            decisions.append(decide_final(row[1], annotator1, annotator2))\n",
    "        \n",
    "        slice_df['category'] = decisions\n",
    "        slice_df = slice_df.loc[:, ~slice_df.columns.isin(['course', 'category_'+annotator1, 'category_'+annotator2])]\n",
    "        slice_df.to_csv(PATH_final + c + '.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_final_annotation_files('biya', 'jae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_final_annotation_files('min', 'jinhong')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
